import streamlit as st
import tensorflow as tf
import numpy as np
import pickle
import zipfile
import os
from tensorflow.keras.preprocessing.sequence import pad_sequences

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
CLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']
ZIP_PATH = 'model_glove_lstm.zip'  # ZIP-–∞—Ä—Ö–∏–≤ —Å –º–æ–¥–µ–ª—å—é
TOKENIZER_PATH = 'tokenizer.pkl'   # –û—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
def prepare_model():
    # –ï—Å–ª–∏ –ø–∞–ø–∫–∞ –º–æ–¥–µ–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–∞–∫–æ–≤–∫—É
    if os.path.exists('model_glove_savedmodel'):
        return True
        
    if not os.path.exists(ZIP_PATH):
        st.error(f"ZIP-–∞—Ä—Ö–∏–≤ —Å –º–æ–¥–µ–ª—å—é '{ZIP_PATH}' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return False
        
    try:
        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
            zip_ref.extractall()
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    try:
        return tf.keras.models.load_model('model_glove_savedmodel')
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
@st.cache_resource
def load_tokenizer():
    try:
        with open(TOKENIZER_PATH, 'rb') as f:
            return pickle.load(f)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {e}")
        return None

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
def main():
    st.title("üì∞ News Classifier (GloVe+LSTM)")
    st.write("Classifies English news text into 4 categories")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
    if not prepare_model():
        st.stop()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    model = load_model()
    tokenizer = load_tokenizer()
    
    if model is None or tokenizer is None:
        st.stop()
    
    # –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
    text = st.text_area("Enter news text (English only):", height=150,
                       placeholder="Example: Tesla announced new battery technology...")
    
    if st.button("Classify"):
        if not text.strip():
            st.warning("Please enter some text")
        else:
            with st.spinner("Analyzing..."):
                try:
                    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    seq = tokenizer.texts_to_sequences([text])
                    padded = pad_sequences(seq, maxlen=100)
                    pred = model.predict(padded, verbose=0)
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    category = CLASS_NAMES[np.argmax(pred)]
                    confidence = np.max(pred)
                    
                    st.success(f"Category: {category}")
                    st.metric("Confidence", f"{confidence:.1%}")
                    
                    # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
                    with st.expander("Details"):
                        for name, prob in zip(CLASS_NAMES, pred[0]):
                            st.write(f"{name}: {prob:.4f}")
                            
                except Exception as e:
                    st.error(f"Classification error: {e}")

if __name__ == "__main__":
    main()